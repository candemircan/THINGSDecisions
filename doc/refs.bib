@article{shepard_generalisation,
author = {Roger N. Shepard },
title = {Toward a Universal Law of Generalization for Psychological Science},
journal = {Science},
volume = {237},
number = {4820},
pages = {1317-1323},
year = {1987},
doi = {10.1126/science.3629243},
URL = {https://www.science.org/doi/abs/10.1126/science.3629243},
eprint = {https://www.science.org/doi/pdf/10.1126/science.3629243},
abstract = {A psychological space is established for any set of stimuli by determining metric distances between the stimuli such that the probability that a response learned to any stimulus will generalize to any other is an invariant monotonic function of the distance between them. To a good approximation, this probability of generalization (i) decays exponentially with this distance, and (ii) does so in accordance with one of two metrics, depending on the relation between the dimensions along which the stimuli vary. These empirical regularities are mathematically derivable from universal principles of natural kinds and probabilistic geometry that may, through evolutionary internalization, tend to govern the behaviors of all sentient organisms.}}
@article{stojic_its_2020,
	title = {It’s new, but is it good? {How} generalization and uncertainty guide the exploration of novel options.},
	volume = {149},
	issn = {1939-2222, 0096-3445},
	shorttitle = {It’s new, but is it good?},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xge0000749},
	doi = {10.1037/xge0000749},
	abstract = {How do people decide whether to try out novel options as opposed to tried-and-tested ones? We argue that they infer a novel option’s reward from contextual information learned from functional relations and take uncertainty into account when making a decision. We propose a Bayesian optimization model to describe their learning and decision making. This model relies on similarity-based learning of functional relationships between features and rewards, and a choice rule that balances exploration and exploitation by combining predicted rewards and the uncertainty of these predictions. Our model makes 2 main predictions. First, decision makers who learn functional relationships will generalize based on the learned reward function, choosing novel options only if their predicted reward is high. Second, they will take uncertainty about the function into account, and prefer novel options that can reduce this uncertainty. We test these predictions in 3 preregistered experiments in which we examine participants’ preferences for novel options using a feature-based multiarmed bandit task in which rewards are a noisy function of observable features. Our results reveal strong evidence for functional exploration and moderate evidence for uncertainty-guided exploration. However, whether or not participants chose a novel option also depended on their attention, as well as reflecting on the value of the options. These results advance our understanding of people’s reactions in the face of novelty.},
	language = {en},
	number = {10},
	urldate = {2022-01-11},
	journal = {Journal of Experimental Psychology: General},
	author = {Stojić, Hrvoje and Schulz, Eric and P. Analytis, Pantelis and Speekenbrink, Maarten},
	month = oct,
	year = {2020},
	pages = {1878--1907},
	file = {Stojić et al. - 2020 - It’s new, but is it good How generalization and u.pdf:/home/can/Zotero/storage/P7P6TIMT/Stojić et al. - 2020 - It’s new, but is it good How generalization and u.pdf:application/pdf},
}

@article{lucas2015rational,
  title={A rational model of function learning},
  author={Lucas, Christopher G and Griffiths, Thomas L and Williams, Joseph J and Kalish, Michael L},
  journal={Psychonomic bulletin \& review},
  volume={22},
  number={5},
  pages={1193--1215},
  year={2015},
  publisher={Springer}
}


@article{shanks1998feature,
  title={Feature-and rule-based generalization in human associative learning.},
  author={Shanks, David R and Darby, Richard J},
  journal={Journal of Experimental Psychology: Animal Behavior Processes},
  volume={24},
  number={4},
  pages={405},
  year={1998},
  publisher={American Psychological Association}
}


@article{schulz2017compositional,
  title={Compositional inductive biases in function learning},
  author={Schulz, Eric and Tenenbaum, Joshua B and Duvenaud, David and Speekenbrink, Maarten and Gershman, Samuel J},
  journal={Cognitive psychology},
  volume={99},
  pages={44--79},
  year={2017},
  publisher={Elsevier}
}


@article{rieskamp2006ssl,
  title={SSL: a theory of how people learn to select strategies.},
  author={Rieskamp, J{\"o}rg and Otto, Philipp E},
  journal={Journal of Experimental Psychology: General},
  volume={135},
  number={2},
  pages={207},
  year={2006},
  publisher={American Psychological Association}
}

@article{saanum2021compositional,
  title={Compositional generalization in multi-armed bandits},
  author={Saanum, Tankred and Schulz, Eric and Speekenbrink, Maarten},
  year={2021},
  journal={PsyArXiv}
}

@book{bishop2006,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
year = {2006},
isbn = {0387310738},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@article{gluck2002people,
  title={How do people solve the “weather prediction” task?: Individual variability in strategies for probabilistic category learning},
  author={Gluck, Mark A and Shohamy, Daphna and Myers, Catherine},
  journal={Learning \& Memory},
  volume={9},
  number={6},
  pages={408--418},
  year={2002},
  publisher={Cold Spring Harbor Lab}
}


@article{mata2007aging,
  title={The aging decision maker: cognitive aging and the adaptive selection of decision strategies.},
  author={Mata, Rui and Schooler, Lael J and Rieskamp, J{\"o}rg},
  journal={Psychology and aging},
  volume={22},
  number={4},
  pages={796},
  year={2007},
  publisher={American psychological association}
}


@article{juslin2003exemplar,
  title={Exemplar effects in categorization and multiple-cue judgment.},
  author={Juslin, Peter and Olsson, Henrik and Olsson, Anna-Carin},
  journal={Journal of Experimental Psychology: General},
  volume={132},
  number={1},
  pages={133},
  year={2003},
  publisher={American Psychological Association}
}



@article{niv_reinforcement_2015,
	title = {Reinforcement {Learning} in {Multidimensional} {Environments} {Relies} on {Attention} {Mechanisms}},
	volume = {35},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4444538/},
	doi = {10.1523/JNEUROSCI.2978-14.2015},
	abstract = {In recent years, ideas from the computational field of reinforcement learning have revolutionized the study of learning in the brain, famously providing new, precise theories of how dopamine affects learning in the basal ganglia. However, reinforcement learning algorithms are notorious for not scaling well to multidimensional environments, as is required for real-world learning. We hypothesized that the brain naturally reduces the dimensionality of real-world problems to only those dimensions that are relevant to predicting reward, and conducted an experiment to assess by what algorithms and with what neural mechanisms this “representation learning” process is realized in humans. Our results suggest that a bilateral attentional control network comprising the intraparietal sulcus, precuneus, and dorsolateral prefrontal cortex is involved in selecting what dimensions are relevant to the task at hand, effectively updating the task representation through trial and error. In this way, cortical attention mechanisms interact with learning in the basal ganglia to solve the “curse of dimensionality” in reinforcement learning.},
	number = {21},
	urldate = {2022-01-11},
	journal = {The Journal of Neuroscience},
	author = {Niv, Yael and Daniel, Reka and Geana, Andra and Gershman, Samuel J. and Leong, Yuan Chang and Radulescu, Angela and Wilson, Robert C.},
	month = may,
	year = {2015},
	pmid = {26019331},
	pmcid = {PMC4444538},
	pages = {8145--8157},
	file = {PubMed Central Full Text PDF:/home/can/Zotero/storage/RITBU9FI/Niv et al. - 2015 - Reinforcement Learning in Multidimensional Environ.pdf:application/pdf},
}

@techreport{saanum_compositional_2021,
	type = {preprint},
	title = {Compositional generalization in multi-armed bandits},
	url = {https://osf.io/v6mzb},
	abstract = {To what extent do human reward learning and decision-making rely on the ability to represent and generate richly structured relationships between options? We provide evidence that structure learning and the principle of compositionality play crucial roles in human reinforcement learning. In a new multiarmed bandit paradigm, we found evidence that participants are able to learn representations of different reward structures and combine them to make correct generalizations about options in novel contexts. Moreover, we found substantial evidence that participants transferred knowledge of simpler reward structures to make compositional generalizations about rewards in complex contexts. This allowed participants to accumulate more rewards earlier, and to explore less whenever such knowledge transfer was possible. We also provide a computational model which is able to generalize and compose knowledge for complex reward structures. This model describes participant behaviour in the compositional generalization task better than various other models of decision-making and transfer learning.},
	language = {en},
	urldate = {2022-01-11},
	institution = {PsyArXiv},
	author = {Saanum, Tankred and Schulz, Eric and Speekenbrink, Maarten},
	month = may,
	year = {2021},
	doi = {10.31234/osf.io/v6mzb},
	file = {Saanum et al. - 2021 - Compositional generalization in multi-armed bandit.pdf:/home/can/Zotero/storage/QIH5GUUM/Saanum et al. - 2021 - Compositional generalization in multi-armed bandit.pdf:application/pdf},
}

@article{binz_heuristics_2022,
	title = {Heuristics from bounded meta-learned inference},
	issn = {1939-1471},
	doi = {10.1037/rev0000330},
	abstract = {Numerous researchers have put forward heuristics as models of human decision-making. However, where such heuristics come from is still a topic of ongoing debate. In this work, we propose a novel computational model that advances our understanding of heuristic decision-making by explaining how different heuristics are discovered and how they are selected. This model-called bounded meta-learned inference (BMI)-is based on the idea that people make environment-specific inferences about which strategies to use while being efficient in terms of how they use computational resources. We show that our approach discovers two previously suggested types of heuristics-one reason decision-making and equal weighting-in specific environments. Furthermore, the model provides clear and precise predictions about when each heuristic should be applied: Knowing the correct ranking of attributes leads to one reason decision-making, knowing the directions of the attributes leads to equal weighting, and not knowing about either leads to strategies that use weighted combinations of multiple attributes. In three empirical paired comparison studies with continuous features, we verify predictions of our theory and show that it captures several characteristics of human decision-making not explained by alternative theories. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
	language = {eng},
	journal = {Psychological Review},
	author = {Binz, Marcel and Gershman, Samuel J. and Schulz, Eric and Endres, Dominik},
	month = jan,
	year = {2022},
	pmid = {34990160},
}

@article{hebart_revealing_2020,
	title = {Revealing the multidimensional mental representations of natural objects underlying human similarity judgements},
	volume = {4},
	copyright = {2020 This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-020-00951-3},
	doi = {10.1038/s41562-020-00951-3},
	abstract = {Objects can be characterized according to a vast number of possible criteria (such as animacy, shape, colour and function), but some dimensions are more useful than others for making sense of the objects around us. To identify these core dimensions of object representations, we developed a data-driven computational model of similarity judgements for real-world images of 1,854 objects. The model captured most explainable variance in similarity judgements and produced 49 highly reproducible and meaningful object dimensions that reflect various conceptual and perceptual properties of those objects. These dimensions predicted external categorization behaviour and reflected typicality judgements of those categories. Furthermore, humans can accurately rate objects along these dimensions, highlighting their interpretability and opening up a way to generate similarity estimates from object dimensions alone. Collectively, these results demonstrate that human similarity judgements can be captured by a fairly low-dimensional, interpretable embedding that generalizes to external behaviour.},
	language = {en},
	number = {11},
	urldate = {2022-01-11},
	journal = {Nature Human Behaviour},
	author = {Hebart, Martin N. and Zheng, Charles Y. and Pereira, Francisco and Baker, Chris I.},
	month = nov,
	year = {2020},
	keywords = {Computational models, Human behaviour, Perception},
	pages = {1173--1185},
	file = {Full Text PDF:/home/can/Zotero/storage/K8W8Q42X/Hebart et al. - 2020 - Revealing the multidimensional mental representati.pdf:application/pdf;Snapshot:/home/can/Zotero/storage/Y39E4F57/s41562-020-00951-3.html:text/html},
}

@article{hebart_things_2019,
	title = {{THINGS}: {A} database of 1,854 object concepts and more than 26,000 naturalistic object images},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {{THINGS}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0223792},
	doi = {10.1371/journal.pone.0223792},
	abstract = {In recent years, the use of a large number of object concepts and naturalistic object images has been growing strongly in cognitive neuroscience research. Classical databases of object concepts are based mostly on a manually curated set of concepts. Further, databases of naturalistic object images typically consist of single images of objects cropped from their background, or a large number of naturalistic images of varying quality, requiring elaborate manual image curation. Here we provide a set of 1,854 diverse object concepts sampled systematically from concrete picturable and nameable nouns in the American English language. Using these object concepts, we conducted a large-scale web image search to compile a database of 26,107 high-quality naturalistic images of those objects, with 12 or more object images per concept and all images cropped to square size. Using crowdsourcing, we provide higher-level category membership for the 27 most common categories and validate them by relating them to representations in a semantic embedding derived from large text corpora. Finally, by feeding images through a deep convolutional neural network, we demonstrate that they exhibit high selectivity for different object concepts, while at the same time preserving variability of different object images within each concept. Together, the THINGS database provides a rich resource of object concepts and object images and offers a tool for both systematic and large-scale naturalistic research in the fields of psychology, neuroscience, and computer science.},
	language = {en},
	number = {10},
	urldate = {2022-01-11},
	journal = {PLOS ONE},
	author = {Hebart, Martin N. and Dickter, Adam H. and Kidder, Alexis and Kwok, Wan Y. and Corriveau, Anna and Wicklin, Caitlin Van and Baker, Chris I.},
	month = oct,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Computational neuroscience, Computer and information sciences, Computer imaging, Graphical user interfaces, Neural networks, Semantics, Vision, Visual object recognition},
	pages = {e0223792},
	file = {Full Text PDF:/home/can/Zotero/storage/ATWBBF57/Hebart et al. - 2019 - THINGS A database of 1,854 object concepts and mo.pdf:application/pdf;Snapshot:/home/can/Zotero/storage/Q9HDSVXZ/article.html:text/html},
}

@article{collins_advances_2022,
	title = {Advances in modeling learning and decision-making in neuroscience},
	volume = {47},
	issn = {0893-133X, 1740-634X},
	url = {https://www.nature.com/articles/s41386-021-01126-y},
	doi = {10.1038/s41386-021-01126-y},
	language = {en},
	number = {1},
	urldate = {2022-01-11},
	journal = {Neuropsychopharmacology},
	author = {Collins, Anne G. E. and Shenhav, Amitai},
	month = jan,
	year = {2022},
	pages = {104--118},
	file = {Collins and Shenhav - 2022 - Advances in modeling learning and decision-making .pdf:/home/can/Zotero/storage/UM8C6SW6/Collins and Shenhav - 2022 - Advances in modeling learning and decision-making .pdf:application/pdf},
}

@inproceedings{rescorla_theory_1972,
	title = {A theory of {Pavlovian} conditioning : {Variations} in the effectiveness of reinforcement and nonreinforcement},
	author = {Rescorla, Robert},
	year = {1972},
}

@article{speekenbrink_learning_2010,
	title = {Learning in a changing environment},
	volume = {139},
	issn = {1939-2222},
	doi = {10.1037/a0018620},
	abstract = {Multiple cue probability learning studies have typically focused on stationary environments. We present 3 experiments investigating learning in changing environments. A fine-grained analysis of the learning dynamics shows that participants were responsive to both abrupt and gradual changes in cue-outcome relations. We found no evidence that participants adapted to these types of change in qualitatively different ways. Also, in contrast to earlier claims that these tasks are learned implicitly, participants showed good insight into what they learned. By fitting formal learning models, we investigated whether participants learned global functional relationships or made localized predictions from similar experienced exemplars. Both a local (the associative learning model) and a global learning model (the Bayesian linear filter) fitted the data of the first 2 experiments. However, the results of Experiment 3, which was specifically designed to discriminate between local and global learning models, provided more support for global learning models. Finally, we present a novel model to account for the cue competition effects found in previous research and displayed by some of our participants.},
	language = {eng},
	number = {2},
	journal = {Journal of Experimental Psychology. General},
	author = {Speekenbrink, Maarten and Shanks, David R.},
	month = may,
	year = {2010},
	pmid = {20438252},
	keywords = {Adult, Analysis of Variance, Attention, Cognition, Cues, Environment, Female, Humans, Male, Models, Psychological, Probability Learning, Problem Solving},
	pages = {266--298},
	file = {Submitted Version:/home/can/Zotero/storage/Y2672Q6T/Speekenbrink and Shanks - 2010 - Learning in a changing environment.pdf:application/pdf},
}

@inproceedings{stojic_human_2015,
	title = {Human behavior in contextual multi-armed bandit problems},
	author = {Stojic, Hrvoje and Analytis, Pantelis and Speekenbrink, Maarten},
	month = jul,
	year = {2015},
}

@article{schulz_tutorial_2018,
	title = {A tutorial on {Gaussian} process regression: {Modelling}, exploring, and exploiting functions},
	volume = {85},
	issn = {0022-2496},
	shorttitle = {A tutorial on {Gaussian} process regression},
	url = {https://www.sciencedirect.com/science/article/pii/S0022249617302158},
	doi = {10.1016/j.jmp.2018.03.001},
	abstract = {This tutorial introduces the reader to Gaussian process regression as an expressive tool to model, actively explore and exploit unknown functions. Gaussian process regression is a powerful, non-parametric Bayesian approach towards regression problems that can be utilized in exploration and exploitation scenarios. This tutorial aims to provide an accessible introduction to these techniques. We will introduce Gaussian processes which generate distributions over functions used for Bayesian non-parametric regression, and demonstrate their use in applications and didactic examples including simple regression problems, a demonstration of kernel-encoded prior assumptions and compositions, a pure exploration scenario within an optimal design framework, and a bandit-like exploration–exploitation scenario where the goal is to recommend movies. Beyond that, we describe a situation modelling risk-averse exploration in which an additional constraint (not to sample below a certain threshold) needs to be accounted for. Lastly, we summarize recent psychological experiments utilizing Gaussian processes. Software and literature pointers are also provided.},
	language = {en},
	urldate = {2022-01-15},
	journal = {Journal of Mathematical Psychology},
	author = {Schulz, Eric and Speekenbrink, Maarten and Krause, Andreas},
	month = aug,
	year = {2018},
	keywords = {Active learning, Bandit problems, Exploration–exploitation, Gaussian process regression},
	pages = {1--16},
	file = {Submitted Version:/home/can/Zotero/storage/JPNZI4L5/Schulz et al. - 2018 - A tutorial on Gaussian process regression Modelli.pdf:application/pdf;ScienceDirect Snapshot:/home/can/Zotero/storage/AQE2GN59/S0022249617302158.html:text/html},
}

@article{schulz_finding_2020,
	title = {Finding structure in multi-armed bandits},
	volume = {119},
	issn = {1095-5623},
	doi = {10.1016/j.cogpsych.2019.101261},
	abstract = {How do humans search for rewards? This question is commonly studied using multi-armed bandit tasks, which require participants to trade off exploration and exploitation. Standard multi-armed bandits assume that each option has an independent reward distribution. However, learning about options independently is unrealistic, since in the real world options often share an underlying structure. We study a class of structured bandit tasks, which we use to probe how generalization guides exploration. In a structured multi-armed bandit, options have a correlation structure dictated by a latent function. We focus on bandits in which rewards are linear functions of an option’s spatial position. Across 5 experiments, we find evidence that participants utilize functional structure to guide their exploration, and also exhibit a learning-to-learn effect across rounds, becoming progressively faster at identifying the latent function. Our experiments rule out several heuristic explanations and show that the same findings obtain with non-linear functions. Comparing several models of learning and decision making, we find that the best model of human behavior in our tasks combines three computational mechanisms: (1) function learning, (2) clustering of reward distributions across rounds, and (3) uncertainty-guided exploration. Our results suggest that human reinforcement learning can utilize latent structure in sophisticated ways to improve efficiency. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	journal = {Cognitive Psychology},
	author = {Schulz, Eric and Franklin, Nicholas T. and Gershman, Samuel J.},
	year = {2020},
	note = {Place: Netherlands
Publisher: Elsevier Science},
	keywords = {Decision Making, Generalization (Learning), Heuristics, Reinforcement, Rewards},
	file = {Snapshot:/home/can/Zotero/storage/AIG5VNZG/2020-38222-001.html:text/html;Submitted Version:/home/can/Zotero/storage/SPTZIUCV/Schulz et al. - 2020 - Finding structure in multi-armed bandits.pdf:application/pdf},
}

@inproceedings{griffiths_modeling_2009,
	title = {Modeling human function learning with {Gaussian} processes},
	volume = {21},
	url = {https://papers.nips.cc/paper/2008/hash/07c5807d0d927dcd0980f86024e5208b-Abstract.html},
	urldate = {2022-01-15},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Griffiths, Thomas and Lucas, Chris and Williams, Joseph and Kalish, Michael},
	year = {2009},
	file = {Full Text PDF:/home/can/Zotero/storage/WLHJSMCM/Griffiths et al. - 2009 - Modeling human function learning with Gaussian pro.pdf:application/pdf},
}

@article{dawes_linear_1974,
	title = {Linear models in decision making},
	volume = {81},
	issn = {1939-1455},
	doi = {10.1037/h0037613},
	abstract = {A review of the literature indicates that linear models are frequently used in situations in which decisions are made on the basis of multiple codable inputs. These models are sometimes used (a) normatively to aid the decision maker, (b) as a contrast with the decision maker in the clinical vs statistical controversy, (c) to represent the decision maker "paramorphically" and (d) to "bootstrap" the decision maker by replacing him with his representation. Examination of the contexts in which linear models have been successfully employed indicates that the contexts have the following structural characteristics in common: each input variable has a conditionally monotone relationship with the output; there is error of measurement; and deviations from optimal weighting do not make much practical difference. These characteristics ensure the success of linear models, which are so appropriate in such contexts that random linear models (i.e., models whose weights are randomly chosen except for sign) may perform quite well. 4 examples involving the prediction of such codable output variables as GPA and psychiatric diagnosis are analyzed in detail. In all 4 examples, random linear models yield predictions that are superior to those of human judges. (52 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Bulletin},
	author = {Dawes, Robyn M. and Corrigan, Bernard},
	year = {1974},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Decision Making, Prediction, Statistical Analysis},
	pages = {95--106},
	file = {Snapshot:/home/can/Zotero/storage/75894F6U/1975-22200-001.html:text/html},
}

@article{battleday_convolutional_2021,
	title = {From convolutional neural networks to models of higher-level cognition (and back again)},
	volume = {1505},
	issn = {1749-6632},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/nyas.14593},
	doi = {10.1111/nyas.14593},
	abstract = {The remarkable successes of convolutional neural networks (CNNs) in modern computer vision are by now well known, and they are increasingly being explored as computational models of the human visual system. In this paper, we ask whether CNNs might also provide a basis for modeling higher-level cognition, focusing on the core phenomena of similarity and categorization. The most important advance comes from the ability of CNNs to learn high-dimensional representations of complex naturalistic images, substantially extending the scope of traditional cognitive models that were previously only evaluated with simple artificial stimuli. In all cases, the most successful combinations arise when CNN representations are used with cognitive models that have the capacity to transform them to better fit human behavior. One consequence of these insights is a toolkit for the integration of cognitively motivated constraints back into CNN training paradigms in computer vision and machine learning, and we review cases where this leads to improved performance. A second consequence is a roadmap for how CNNs and cognitive models can be more fully integrated in the future, allowing for flexible end-to-end algorithms that can learn representations from data while still retaining the structured behavior characteristic of human cognition.},
	language = {en},
	number = {1},
	urldate = {2022-01-17},
	journal = {Annals of the New York Academy of Sciences},
	author = {Battleday, Ruairidh M. and Peterson, Joshua C. and Griffiths, Thomas L.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/nyas.14593},
	keywords = {categorization, cognitive modeling, convolutional neural networks, similarity, vision},
	pages = {55--78},
	file = {Full Text PDF:/home/can/Zotero/storage/73D3TX4R/Battleday et al. - 2021 - From convolutional neural networks to models of hi.pdf:application/pdf;Snapshot:/home/can/Zotero/storage/8R37UCF6/nyas.html:text/html},
}

@article{stephan_bayesian_2009,
	title = {Bayesian model selection for group studies},
	volume = {46},
	issn = {1095-9572},
	doi = {10.1016/j.neuroimage.2009.03.025},
	abstract = {Bayesian model selection (BMS) is a powerful method for determining the most likely among a set of competing hypotheses about the mechanisms that generated observed data. BMS has recently found widespread application in neuroimaging, particularly in the context of dynamic causal modelling (DCM). However, so far, combining BMS results from several subjects has relied on simple (fixed effects) metrics, e.g. the group Bayes factor (GBF), that do not account for group heterogeneity or outliers. In this paper, we compare the GBF with two random effects methods for BMS at the between-subject or group level. These methods provide inference on model-space using a classical and Bayesian perspective respectively. First, a classical (frequentist) approach uses the log model evidence as a subject-specific summary statistic. This enables one to use analysis of variance to test for differences in log-evidences over models, relative to inter-subject differences. We then consider the same problem in Bayesian terms and describe a novel hierarchical model, which is optimised to furnish a probability density on the models themselves. This new variational Bayes method rests on treating the model as a random variable and estimating the parameters of a Dirichlet distribution which describes the probabilities for all models considered. These probabilities then define a multinomial distribution over model space, allowing one to compute how likely it is that a specific model generated the data of a randomly chosen subject as well as the exceedance probability of one model being more likely than any other model. Using empirical and synthetic data, we show that optimising a conditional density of the model probabilities, given the log-evidences for each model over subjects, is more informative and appropriate than both the GBF and frequentist tests of the log-evidences. In particular, we found that the hierarchical Bayesian approach is considerably more robust than either of the other approaches in the presence of outliers. We expect that this new random effects method will prove useful for a wide range of group studies, not only in the context of DCM, but also for other modelling endeavours, e.g. comparing different source reconstruction methods for EEG/MEG or selecting among competing computational models of learning and decision-making.},
	language = {eng},
	number = {4},
	journal = {NeuroImage},
	author = {Stephan, Klaas Enno and Penny, Will D. and Daunizeau, Jean and Moran, Rosalyn J. and Friston, Karl J.},
	month = jul,
	year = {2009},
	pmid = {19306932},
	pmcid = {PMC2703732},
	keywords = {Algorithms, Bayes Theorem, Brain, Cognition, Diagnostic Imaging, Humans, Models, Neurological},
	pages = {1004--1017},
	file = {Accepted Version:/home/can/Zotero/storage/95G2A22V/Stephan et al. - 2009 - Bayesian model selection for group studies.pdf:application/pdf},
}

@article{wu_generalization_2018,
	title = {Generalization guides human exploration in vast decision spaces},
	volume = {2},
	issn = {2397-3374},
	url = {https://doi.org/10.1038/s41562-018-0467-4},
	doi = {10.1038/s41562-018-0467-4},
	abstract = {From foraging for food to learning complex games, many aspects of human behaviour can be framed as a search problem with a vast space of possible actions. Under finite search horizons, optimal solutions are generally unobtainable. Yet, how do humans navigate vast problem spaces, which require intelligent exploration of unobserved actions? Using various bandit tasks with up to 121 arms, we study how humans search for rewards under limited search horizons, in which the spatial correlation of rewards (in both generated and natural environments) provides traction for generalization. Across various different probabilistic and heuristic models, we find evidence that Gaussian process function learning—combined with an optimistic upper confidence bound sampling strategy—provides a robust account of how people use generalization to guide search. Our modelling results and parameter estimates are recoverable and can be used to simulate human-like performance, providing insights about human behaviour in complex environments.},
	number = {12},
	journal = {Nature Human Behaviour},
	author = {Wu, Charley M. and Schulz, Eric and Speekenbrink, Maarten and Nelson, Jonathan D. and Meder, Björn},
	month = dec,
	year = {2018},
	pages = {915--924},
}

@article{gigerenzer_heuristic_2011,
	title = {Heuristic {Decision} {Making}},
	volume = {62},
	url = {https://doi.org/10.1146/annurev-psych-120709-145346},
	doi = {10.1146/annurev-psych-120709-145346},
	abstract = {As reflected in the amount of controversy, few areas in psychology have undergone such dramatic conceptual changes in the past decade as the emerging science of heuristics. Heuristics are efficient cognitive processes, conscious or unconscious, that ignore part of the information. Because using heuristics saves effort, the classical view has been that heuristic decisions imply greater errors than do “rational” decisions as defined by logic or statistical models. However, for many decisions, the assumptions of rational models are not met, and it is an empirical rather than an a priori issue how well cognitive heuristics function in an uncertain world. To answer both the descriptive question (“Which heuristics do people use in which situations?”) and the prescriptive question (“When should people rely on a given heuristic rather than a complex strategy to make better judgments?”), formal models are indispensable. We review research that tests formal models of heuristic inference, including in business organizations, health care, and legal institutions. This research indicates that (a) individuals and organizations often rely on simple heuristics in an adaptive way, and (b) ignoring part of the information can lead to more accurate judgments than weighting and adding all information, for instance for low predictability and small samples. The big future challenge is to develop a systematic theory of the building blocks of heuristics as well as the core capacities and environmental structures these exploit.},
	number = {1},
	urldate = {2022-01-17},
	journal = {Annual Review of Psychology},
	author = {Gigerenzer, Gerd and Gaissmaier, Wolfgang},
	year = {2011},
	pmid = {21126183},
	note = {\_eprint: https://doi.org/10.1146/annurev-psych-120709-145346},
	keywords = {accuracy-effort trade-off, business decisions, ecological rationality, legal decision making, medical decision making, social intelligence},
	pages = {451--482},
	file = {Full Text:/home/can/Zotero/storage/6QNJSS96/Gigerenzer and Gaissmaier - 2011 - Heuristic Decision Making.pdf:application/pdf},
}

@incollection{gigerenzer_betting_1999,
	address = {New York, NY, US},
	series = {Evolution and cognition},
	title = {Betting on one good reason: {The} take the best heuristic},
	isbn = {978-0-19-512156-8},
	shorttitle = {Betting on one good reason},
	abstract = {Analyzes heuristics that draw from inferences from information beyond mere recognition. The authors address how people make inferences, predictions, and decisions from a bundle of imperfect cues and signals. Three heuristics studied in the chapter are the Minimalist, Take The Last, and Take The Best. Findings indicate that fast and frugal heuristics that embody simple psychological mechanisms can yield inferences about a real-world environment that are at least as accurate as standard linear statistical strategies embodying classical properties of rational judgment. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	booktitle = {Simple heuristics that make us smart},
	publisher = {Oxford University Press},
	author = {Gigerenzer, Gerd and Goldstein, Daniel G.},
	year = {1999},
	keywords = {Cues, Decision Making, Heuristic Modeling, Heuristics, Inference},
	pages = {75--95},
	file = {Snapshot:/home/can/Zotero/storage/V73D3PCI/1999-04366-004.html:text/html},
}


@techreport{garvert_hippocampal_2021,
  title={Hippocampal spatio-temporal cognitive maps adaptively guide reward generalization},
  author={Garvert, Mona M and Saanum, Tankred and Schulz, Eric and Schuck, Nicolas W and Doeller, Christian F},
  journal={bioRxiv},
  year={2021},
  publisher={Cold Spring Harbor Laboratory}
}

@article{dawes_linear_1974-1,
	title = {Linear models in decision making},
	volume = {81},
	issn = {1939-1455},
	doi = {10.1037/h0037613},
	abstract = {A review of the literature indicates that linear models are frequently used in situations in which decisions are made on the basis of multiple codable inputs. These models are sometimes used (a) normatively to aid the decision maker, (b) as a contrast with the decision maker in the clinical vs statistical controversy, (c) to represent the decision maker "paramorphically" and (d) to "bootstrap" the decision maker by replacing him with his representation. Examination of the contexts in which linear models have been successfully employed indicates that the contexts have the following structural characteristics in common: each input variable has a conditionally monotone relationship with the output; there is error of measurement; and deviations from optimal weighting do not make much practical difference. These characteristics ensure the success of linear models, which are so appropriate in such contexts that random linear models (i.e., models whose weights are randomly chosen except for sign) may perform quite well. 4 examples involving the prediction of such codable output variables as GPA and psychiatric diagnosis are analyzed in detail. In all 4 examples, random linear models yield predictions that are superior to those of human judges. (52 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Bulletin},
	author = {Dawes, Robyn M. and Corrigan, Bernard},
	year = {1974},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Decision Making, Prediction, Statistical Analysis},
	pages = {95--106},
	file = {Snapshot:/home/can/Zotero/storage/FDKY5CTG/1975-22200-001.html:text/html},
}

@article{yamins_using_2016,
	title = {Using goal-driven deep learning models to understand sensory cortex},
	volume = {19},
	copyright = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.4244},
	doi = {10.1038/nn.4244},
	abstract = {Recent computational neuroscience developments have used deep neural networks to model neural responses in higher visual areas. This Perspective describes key algorithmic underpinnings in computer vision and artificial intelligence that have contributed to this progress and outlines how deep networks could drive future improvements in understanding sensory cortical processing.},
	language = {en},
	number = {3},
	urldate = {2022-01-17},
	journal = {Nature Neuroscience},
	author = {Yamins, Daniel L. K. and DiCarlo, James J.},
	month = mar,
	year = {2016},
	keywords = {Computational neuroscience, Object vision},
	pages = {356--365},
	file = {Full Text PDF:/home/can/Zotero/storage/A6TP7BI4/Yamins and DiCarlo - 2016 - Using goal-driven deep learning models to understa.pdf:application/pdf;Snapshot:/home/can/Zotero/storage/TXZ83UXQ/nn.html:text/html},
}

@inproceedings{he_deep_2016,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	doi = {10.1109/CVPR.2016.90},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = jun,
	year = {2016},
	note = {ISSN: 1063-6919},
	keywords = {Complexity theory, Degradation, Image recognition, Image segmentation, Neural networks, Training, Visualization},
	pages = {770--778},
	file = {IEEE Xplore Abstract Record:/home/can/Zotero/storage/FE6LJWJW/7780459.html:text/html;Submitted Version:/home/can/Zotero/storage/UPBG3D3P/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@article{mcfadden_conditional_1974,
	series = {Frontiers in econometrics. - {New} {York} [u.a.] : {Academic} {Press}, {ISBN} 0-12-776150-0. - 1974, p. 105-142},
	title = {Conditional logit analysis of qualitative choice behavior},
	journal = {Frontiers in econometrics},
	author = {McFadden, Daniel},
	year = {1974},
	file = {Conditional logit analysis of qualitative choice behavior - EconBiz:/home/can/Zotero/storage/PMAUVK9P/10002395479.html:text/html},
}


@article{rigoux_bayesian_2014,
	title = {Bayesian model selection for group studies — {Revisited}},
	volume = {84},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811913009300},
	doi = {10.1016/j.neuroimage.2013.08.065},
	abstract = {In this paper, we revisit the problem of Bayesian model selection (BMS) at the group level. We originally addressed this issue in Stephan et al. (2009), where models are treated as random effects that could differ between subjects, with an unknown population distribution. Here, we extend this work, by (i) introducing the Bayesian omnibus risk (BOR) as a measure of the statistical risk incurred when performing group BMS, (ii) highlighting the difference between random effects BMS and classical random effects analyses of parameter estimates, and (iii) addressing the problem of between group or condition model comparisons. We address the first issue by quantifying the chance likelihood of apparent differences in model frequencies. This leads to the notion of protected exceedance probabilities. The second issue arises when people want to ask “whether a model parameter is zero or not” at the group level. Here, we provide guidance as to whether to use a classical second-level analysis of parameter estimates, or random effects BMS. The third issue rests on the evidence for a difference in model labels or frequencies across groups or conditions. Overall, we hope that the material presented in this paper finesses the problems of group-level BMS in the analysis of neuroimaging and behavioural data.},
	language = {en},
	urldate = {2022-01-24},
	journal = {NeuroImage},
	author = {Rigoux, L. and Stephan, K. E. and Friston, K. J. and Daunizeau, J.},
	month = jan,
	year = {2014},
	keywords = {Between-condition comparison, Between-group comparison, DCM, Exceedance probability, Mixed effects, Random effects, Statistical risk},
	pages = {971--985},
}


@article{peterson_evaluating_2018,
	title = {Evaluating (and {Improving}) the {Correspondence} {Between} {Deep} {Neural} {Networks} and {Human} {Representations}},
	volume = {42},
	issn = {1551-6709},
	doi = {10.1111/cogs.12670},
	abstract = {Decades of psychological research have been aimed at modeling how people learn features and categories. The empirical validation of these theories is often based on artificial stimuli with simple representations. Recently, deep neural networks have reached or surpassed human accuracy on tasks such as identifying objects in natural images. These networks learn representations of real-world stimuli that can potentially be leveraged to capture psychological representations. We find that state-of-the-art object classification networks provide surprisingly accurate predictions of human similarity judgments for natural images, but they fail to capture some of the structure represented by people. We show that a simple transformation that corrects these discrepancies can be obtained through convex optimization. We use the resulting representations to predict the difficulty of learning novel categories of natural images. Our results extend the scope of psychological experiments and computational modeling by enabling tractable use of large natural stimulus sets.},
	language = {eng},
	number = {8},
	journal = {Cognitive Science},
	author = {Peterson, Joshua C. and Abbott, Joshua T. and Griffiths, Thomas L.},
	month = nov,
	year = {2018},
	pmid = {30178468},
	keywords = {Artificial intelligence, Categorization, Humans, Learning, Models, Neurological, Neural networks, Neural Networks, Computer, Photic Stimulation, Similarity},
	pages = {2648--2669},
	file = {Full Text:/home/can/Zotero/storage/6NGBQK82/Peterson et al. - 2018 - Evaluating (and Improving) the Correspondence Betw.pdf:application/pdf},
}


@article{battleday_capturing_2020,
  title={Capturing human categorization of natural images by combining deep networks and cognitive models},
  author={Battleday, Ruairidh M and Peterson, Joshua C and Griffiths, Thomas L},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--14},
  year={2020},
  publisher={Nature Publishing Group}
}